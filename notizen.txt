bookscraper: http://books.toscrape.com/
    scrapy startproject bookscraper
    cd bookscraper
    scrapy genspider bookspider books.toscrape.com
    scrapy list
    scrapy shell
    fetch('http://books.toscrape.com/catalogue/category/books_1/')
    response.body  # Check the raw HTML content
    # response.css('article.product_pod h3 a')
    response.css('article.product_pod').get()
    books = response.css('article.product_pod')
    book = books[0]
    book.css('article.product_pod h3 a::attr(title)').get()

    book.css('p.price_color::text').get() # The price of the book
    book.css('article.product_pod h3 a::attr(href)').get() # url of the book
    response.css('li.next a::attr(href)').get()


https://www.youtube.com/watch?v=ExTimuRFn3M&list=PLkhQp3-EGsIi39YF-BE306DDX1xVSTHmn&index=9
https://www.geeksforgeeks.org/scrapy-feed-exports/


Using pdb (Python Debugger)
The pdb module in Python allows you to run your script in debugging mode from the console.
To use pdb:
 
import pdb; pdb.set_trace()

You can insert the following line in your script wherever you want the debugger to start, usually just before or inside the function you want to debug.
Once in the pdb prompt, you can use the following commands:

    n (next): Execute the next line.
    s (step): Step into the function.
    c (continue): Continue execution until the next breakpoint.
    p <variable>: Print the value of a variable.

Using Logging
For more advanced debugging and to keep track of different levels of information (debug, info, warning, error), you can use the logging module.

scrapy crawl chocolatespider
scrapy crawl chocolatespider -O test.csv


# feedexport.py:
params["mtime"] = params["time"].split('+')[0] 
# Neuer Parameter mtime, Zeitzone abschneiden (+00-00)

# chocolatespider.py:
custom_settings = {
    'FEEDS':    {'../data/%(name)s/%(name)s_%(mtime)s.csv': {'format': 'csv',}}
    }
